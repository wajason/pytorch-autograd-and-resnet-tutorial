# ðŸš€ PyTorch Autograd & ResNet Tutorial

This repository is a **hands-on deep learning tutorial** that takes you from **PyTorch Autograd basics** to building **CNNs and ResNet** for **CIFAR-10 classification**.

Itâ€™s designed for learners who want to **understand how PyTorch really works under the hood** instead of just calling high-level APIs.  
Every block is implemented step by step â€” from barebone tensor ops to modular ResNet.

---

## ðŸ“Œ Features
- âœ… **Part I: Autograd** â€” understand PyTorchâ€™s automatic differentiation.
- âœ… **Part II: Barebones ConvNet** â€” implement convolution layers manually with tensors.
- âœ… **Part III: nn.Module API** â€” build a reusable `ThreeLayerConvNet`.
- âœ… **Part IV: Sequential API** â€” compact model definitions with `nn.Sequential`.
- âœ… **Part V: ResNet for CIFAR-10** â€” implement `PlainBlock`, `ResidualBlock`, and `BottleneckBlock`.

---

## ðŸ“‚ Project Structure
```bash
â”œâ”€â”€ helper.py # Utility functions for training/evaluation
â”œâ”€â”€ pytorch_autograd_and_nn.py # Core implementations of CNN & ResNet
â”œâ”€â”€ Pytorch Autograd and NN.ipynb # Jupyter Notebook walkthrough
â””â”€â”€ README.md
```


---

## ðŸš€ Quick Start
Clone this repo and run the notebook:

```bash
git clone https://github.com/wajason/pytorch-autograd-and-resnet-tutorial.git
cd pytorch-autograd-and-resnet-tutorial
jupyter notebook "Pytorch Autograd and NN.ipynb"
```

## ðŸŽ¯ Learning Goals
 1. Deep dive into PyTorch Autograd
 2. Learn ConvNet internals (weights, bias, forward pass)
 3. Understand skip connections & why ResNet works
 4. Gain hands-on experience building deep CNNs from scratch



